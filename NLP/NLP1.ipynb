{"cells":[{"cell_type":"code","execution_count":null,"id":"c5006882","metadata":{"id":"c5006882"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n"]},{"cell_type":"code","execution_count":null,"id":"409086be","metadata":{"id":"409086be"},"outputs":[],"source":["# nltk.download('all')"]},{"cell_type":"markdown","id":"b6b218af","metadata":{"id":"b6b218af"},"source":["# Different Tokenizers"]},{"cell_type":"code","execution_count":null,"id":"870315f2","metadata":{"id":"870315f2"},"outputs":[],"source":["sentence = \"If you want to know what a man’s like, take a good looks at how he treats his inferiors, not his equals. It is our choices, Harry, that show what we truly are, far more than our abilities!\""]},{"cell_type":"markdown","id":"7dea54a0","metadata":{"id":"7dea54a0"},"source":["## 1. WhiteSpace Tokenization"]},{"cell_type":"code","execution_count":null,"id":"e381bbaf","metadata":{"id":"e381bbaf","outputId":"7310fc6f-3fe2-4cf0-d5cf-96a8b1e3e011","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man’s', 'like,', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors,', 'not', 'his', 'equals.', 'It', 'is', 'our', 'choices,', 'Harry,', 'that', 'show', 'what', 'we', 'truly', 'are,', 'far', 'more', 'than', 'our', 'abilities!']\n"]}],"source":["from nltk.tokenize import WhitespaceTokenizer\n","whitespace_tokenized = WhitespaceTokenizer().tokenize(sentence)\n","print(whitespace_tokenized)\n"]},{"cell_type":"markdown","id":"77e9d330","metadata":{"id":"77e9d330"},"source":["## 2. TreeBankWord Tokenization"]},{"cell_type":"code","execution_count":null,"id":"836b7ef2","metadata":{"id":"836b7ef2","outputId":"0ed9f8fa-7e00-404e-915e-97dbd38ce42d","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man’s', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!']\n"]}],"source":["from nltk.tokenize import TreebankWordTokenizer\n","treebank_tokenized = TreebankWordTokenizer().tokenize(sentence)\n","print(treebank_tokenized)"]},{"cell_type":"markdown","id":"d7ad5366","metadata":{"id":"d7ad5366"},"source":["## 3. MWE Tokenization"]},{"cell_type":"code","execution_count":null,"id":"a3c432be","metadata":{"id":"a3c432be","outputId":"77550104-1394-4341-8aa9-56cf900ff54f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['I', 'f', ' ', 'y', 'o', 'u', ' ', 'w', 'a', 'n', 't', ' ', 't', 'o', ' ', 'k', 'n', 'o', 'w', ' ', 'w', 'h', 'a', 't', ' ', 'a', ' ', 'm', 'a', 'n', '’', 's', ' ', 'l', 'i', 'k', 'e', ',', ' ', 't', 'a', 'k', 'e', ' ', 'a', ' ', 'g', 'o', 'o', 'd', ' ', 'l', 'o', 'o', 'k', 's', ' ', 'a', 't', ' ', 'h', 'o', 'w', ' ', 'h_e', ' ', 't', 'r', 'e', 'a', 't', 's', ' ', 'h', 'i', 's', ' ', 'i', 'n', 'f', 'e', 'r', 'i', 'o', 'r', 's', ',', ' ', 'n', 'o', 't', ' ', 'h', 'i', 's', ' ', 'e', 'q', 'u', 'a', 'l', 's', '.', ' ', 'I', 't', ' ', 'i', 's', ' ', 'o', 'u', 'r', ' ', 'c', 'h', 'o', 'i', 'c', 'e', 's', ',', ' ', 'H_a_r_r_y', ',', ' ', 't', 'h', 'a', 't', ' ', 's', 'h', 'o', 'w', ' ', 'w', 'h', 'a', 't', ' ', 'w', 'e', ' ', 't', 'r', 'u', 'l', 'y', ' ', 'a', 'r', 'e', ',', ' ', 'f', 'a', 'r', ' ', 'm', 'o', 'r', 'e', ' ', 't', 'h', 'a', 'n', ' ', 'o', 'u', 'r', ' ', 'a', 'b', 'i', 'l', 'i', 't', 'i', 'e', 's', '!']\n"]}],"source":["from nltk.tokenize import MWETokenizer\n","mwe_tokenizer = MWETokenizer([('he'),('take','a','good')])\n","mwe_tokenizer.add_mwe(('Harry'))\n","mwe_tokenized = mwe_tokenizer.tokenize(sentence)\n","print(mwe_tokenized)"]},{"cell_type":"markdown","id":"2367b000","metadata":{"id":"2367b000"},"source":["## 4. Tweet Tokenization"]},{"cell_type":"code","execution_count":null,"id":"7d95ee19","metadata":{"id":"7d95ee19","outputId":"5df4f622-5683-439e-a61e-28b6c4bbc01a","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!']\n"]}],"source":["from nltk.tokenize import TweetTokenizer\n","tweet_tokenized = TweetTokenizer().tokenize(sentence)\n","print(tweet_tokenized)"]},{"cell_type":"markdown","id":"ce97e433","metadata":{"id":"ce97e433"},"source":["## 5. Punctuation Based Word Tokenization"]},{"cell_type":"code","execution_count":null,"id":"c0e2d6a1","metadata":{"id":"c0e2d6a1","outputId":"03615174-1bae-4546-841f-be2ef4cc1923","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!']\n"]}],"source":["from nltk.tokenize import wordpunct_tokenize\n","print(wordpunct_tokenize(sentence))"]},{"cell_type":"markdown","id":"bceecc9a","metadata":{"id":"bceecc9a"},"source":["## 6. Punctuation Based Sentence Tokenization"]},{"cell_type":"code","execution_count":null,"id":"0ce82bb1","metadata":{"id":"0ce82bb1","outputId":"3d38caa4-7a61-45da-d043-442d92aa10b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['If you want to know what a man’s like, take a good looks at how he treats his inferiors, not his equals.', 'It is our choices, Harry, that show what we truly are, far more than our abilities!']\n"]}],"source":["sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n","sent_tokenized = sent_detector.tokenize(sentence)\n","print(sent_tokenized)"]},{"cell_type":"markdown","id":"d37d88e0","metadata":{"id":"d37d88e0"},"source":["# Different Stemming Techniques"]},{"cell_type":"markdown","id":"b340ae2b","metadata":{"id":"b340ae2b"},"source":["## 1. SnowBallStemming"]},{"cell_type":"code","execution_count":null,"id":"13212e06","metadata":{"id":"13212e06","outputId":"5bac1205-9bd8-4972-8b75-b7fe0a9eccfa","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Before Snowball Stemming\n","['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!'] \n","\n","After Snowball Stemming\n","['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treat', 'his', 'inferior', ',', 'not', 'his', 'equal', '.', 'it', 'is', 'our', 'choic', ',', 'harri', ',', 'that', 'show', 'what', 'we', 'truli', 'are', ',', 'far', 'more', 'than', 'our', 'abil', '!']\n"]}],"source":["from nltk.stem.snowball import SnowballStemmer\n","snowballstemmer = SnowballStemmer(language='english')\n","stem_words = []\n","for w in tweet_tokenized:\n","    x = snowballstemmer.stem(w)\n","    stem_words.append(x)\n","print('Before Snowball Stemming')\n","print(tweet_tokenized,'\\n')\n","\n","print('After Snowball Stemming')\n","print(stem_words)\n"]},{"cell_type":"markdown","id":"de9af18b","metadata":{"id":"de9af18b"},"source":["## 2. Porter Stemming"]},{"cell_type":"code","execution_count":null,"id":"f99c5b06","metadata":{"id":"f99c5b06","outputId":"417cfd71-cc17-474d-8693-8aae0f913ab3","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Before Potter Stemming\n","['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!'] \n","\n","After Potter Stemming\n","['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treat', 'hi', 'inferior', ',', 'not', 'hi', 'equal', '.', 'it', 'is', 'our', 'choic', ',', 'harri', ',', 'that', 'show', 'what', 'we', 'truli', 'are', ',', 'far', 'more', 'than', 'our', 'abil', '!']\n"]}],"source":["from nltk.stem import PorterStemmer\n","porterstemmer = PorterStemmer()\n","stem_words = []\n","for w in tweet_tokenized:\n","    x = porterstemmer.stem(w)\n","    stem_words.append(x)\n","print('Before Potter Stemming')\n","print(tweet_tokenized,'\\n')\n","\n","print('After Potter Stemming')\n","print(stem_words)\n"]},{"cell_type":"markdown","id":"1f161f9f","metadata":{"id":"1f161f9f"},"source":["# Lemmatization"]},{"cell_type":"code","execution_count":null,"id":"046fb6fd","metadata":{"id":"046fb6fd","outputId":"11dc3b15-0435-4e0c-c53e-7d94522f947f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before Lemmatization\n","['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'looks', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.', 'It', 'is', 'our', 'choices', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '!'] \n","\n","After Lemmatization\n","['If', 'you', 'want', 'to', 'know', 'what', 'a', 'man', '’', 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treat', 'his', 'inferior', ',', 'not', 'his', 'equal', '.', 'It', 'is', 'our', 'choice', ',', 'Harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'ability', '!']\n"]}],"source":["from nltk.stem import WordNetLemmatizer\n","\n","wordnet_lemmatizer = WordNetLemmatizer()\n","stem_words = []\n","for w in tweet_tokenized:\n","    x = wordnet_lemmatizer.lemmatize(w)\n","    stem_words.append(x)\n","print('Before Lemmatization')\n","print(tweet_tokenized,'\\n')\n","\n","print('After Lemmatization')\n","print(stem_words)"]},{"cell_type":"code","execution_count":null,"id":"5e023eaf","metadata":{"id":"5e023eaf"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}
